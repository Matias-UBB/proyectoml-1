{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo con datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECCION DATOS DE ENTRENAMIENTO Y TEST , 2023 SE USARAN PARA TEST\n",
    "data_train = pd.read_csv('atp_matches_2000.csv')\n",
    "data_test=pd.read_csv('atp_matches_2023.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the data from 2001 to 2022\n",
    "for i in range(1, 22):\n",
    "    data_train = pd.concat([data_train, pd.read_csv('atp_matches_20' + str(i).zfill(2) + '.csv')])\n",
    "data_train.index = range(0,len(data_train)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player1_id', 'player1_ht', 'player1_age', 'player2_id', 'player2_ht',\n",
      "       'player2_age', 'player1_rank_points', 'player2_rank_points',\n",
      "       'player_id_win', 'surface_encoded', 'player1_hand_encoded',\n",
      "       'player2_hand_encoded', 'tourney_level_encoded',\n",
      "       'player1_entry_encoded', 'player2_entry_encoded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7041/2256230725.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected_train['player_id_win'] = data_selected_train['winner_id']\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las columnas deseadas\n",
    "selected_columns = ['tourney_id', 'surface', 'tourney_level', 'winner_id', 'winner_entry', 'winner_hand', 'winner_ht', 'winner_age', 'loser_id', 'loser_entry', 'loser_hand', 'loser_ht', 'loser_age', 'winner_rank_points', 'loser_rank_points']\n",
    "\n",
    "# Se crea un dataframe con las columnas seleccionadas\n",
    "data_selected_train = data_train[selected_columns]\n",
    "\n",
    "# Crear una nueva columna llamadaplayer_id_win\n",
    "data_selected_train['player_id_win'] = data_selected_train['winner_id']\n",
    "\n",
    "\n",
    "data_selected_train = data_selected_train.rename(columns={\n",
    "    'winner_id': 'player1_id',\n",
    "    'winner_entry': 'player1_entry',\n",
    "    'winner_hand': 'player1_hand',\n",
    "    'winner_ht': 'player1_ht',\n",
    "    'winner_age': 'player1_age',\n",
    "    'winner_rank_points': 'player1_rank_points',\n",
    "    'loser_id': 'player2_id',\n",
    "    'loser_entry': 'player2_entry',\n",
    "    'loser_hand': 'player2_hand',\n",
    "    'loser_ht': 'player2_ht',\n",
    "    'loser_age': 'player2_age',\n",
    "    'loser_rank_points': 'player2_rank_points'\n",
    "})\n",
    "# Mapeo para 'surface'\n",
    "surface_mapping = {'Clay': 0, 'Grass': 1, 'Hard': 2, 'Carpet': 3} \n",
    "data_selected_train['surface_encoded'] = data_selected_train['surface'].map(surface_mapping)\n",
    "\n",
    "# Mapeo para 'winner_hand'\n",
    "hand_mapping = {'R': 0, 'L': 1, 'U': 2}  # Puedes ajustar esto según tus datos\n",
    "data_selected_train['player1_hand_encoded'] = data_selected_train['player1_hand'].map(hand_mapping)\n",
    "data_selected_train['player2_hand_encoded'] = data_selected_train['player2_hand'].map(hand_mapping)\n",
    "data_selected_train = data_selected_train.drop(['surface', 'player1_hand','player2_hand'], axis=1)\n",
    "\n",
    "# Reemplazar el guion '-' con una cadena vacía ''\n",
    "data_selected_train['tourney_id'] = data_selected_train['tourney_id'].str.replace('-', '')\n",
    "\n",
    "\n",
    "tourney_level_mapping = {'G': 0, 'M': 1, 'A': 2, 'C': 3, 'S': 4, 'F': 5, 'D': 6}  # Puedes ajustar esto según tus datos\n",
    "data_selected_train['tourney_level_encoded'] = data_selected_train['tourney_level'].map(tourney_level_mapping)\n",
    "\n",
    "# Eliminar la columna original 'tourney_level'\n",
    "data_selected_train = data_selected_train.drop(['tourney_level'], axis=1)\n",
    "\n",
    "winner_entry_mapping = {'WC': 1, 'Q': 2, 'LL': 3, 'PR': 4} \n",
    "data_selected_train['player1_entry_encoded'] = data_selected_train['player1_entry'].map(winner_entry_mapping)\n",
    "data_selected_train['player2_entry_encoded'] = data_selected_train['player2_entry'].map(winner_entry_mapping)\n",
    "\n",
    "# Eliminar la columna original 'player1_entry' y 'player2_entry'\n",
    "data_selected_train = data_selected_train.drop(['player1_entry', 'player2_entry'], axis=1)\n",
    "# Reemplazar NaN con 0 en 'player1_entry_encoded' y 'player2_entry_encoded'\n",
    "data_selected_train['player1_entry_encoded'].fillna(0, inplace=True)\n",
    "data_selected_train['player2_entry_encoded'].fillna(0, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'tourney_id'\n",
    "data_selected_train = data_selected_train.drop(['tourney_id'], axis=1)\n",
    "data_selected_train = data_selected_train.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "#print(data_selected.head())\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "print(data_selected_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player1_id', 'player1_ht', 'player1_age', 'player2_id', 'player2_ht',\n",
      "       'player2_age', 'player1_rank_points', 'player2_rank_points',\n",
      "       'player_id_win', 'surface_encoded', 'player1_hand_encoded',\n",
      "       'player2_hand_encoded', 'tourney_level_encoded',\n",
      "       'player1_entry_encoded', 'player2_entry_encoded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7041/294209450.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected_test['player_id_win'] = data_selected_test['winner_id']\n"
     ]
    }
   ],
   "source": [
    "# Se crea un dataframe con las columnas seleccionadas\n",
    "data_selected_test = data_test[selected_columns]\n",
    "\n",
    "# Crear una nueva columna llamada player_id_win\n",
    "data_selected_test['player_id_win'] = data_selected_test['winner_id']\n",
    "\n",
    "data_selected_test = data_selected_test.rename(columns={\n",
    "    'winner_id': 'player1_id',\n",
    "    'winner_entry': 'player1_entry',\n",
    "    'winner_hand': 'player1_hand',\n",
    "    'winner_ht': 'player1_ht',\n",
    "    'winner_age': 'player1_age',\n",
    "    'winner_rank_points': 'player1_rank_points',\n",
    "    'loser_id': 'player2_id',\n",
    "    'loser_entry': 'player2_entry',\n",
    "    'loser_hand': 'player2_hand',\n",
    "    'loser_ht': 'player2_ht',\n",
    "    'loser_age': 'player2_age',\n",
    "    'loser_rank_points': 'player2_rank_points'\n",
    "})\n",
    "# Mapeo para 'surface'\n",
    "surface_mapping = {'Clay': 0, 'Grass': 1, 'Hard': 2, 'Carpet': 3} \n",
    "data_selected_test['surface_encoded'] = data_selected_test['surface'].map(surface_mapping)\n",
    "\n",
    "# Mapeo para 'winner_hand'\n",
    "hand_mapping = {'R': 0, 'L': 1, 'U': 2}  # Puedes ajustar esto según tus datos\n",
    "data_selected_test['player1_hand_encoded'] = data_selected_test['player1_hand'].map(hand_mapping)\n",
    "data_selected_test['player2_hand_encoded'] = data_selected_test['player2_hand'].map(hand_mapping)\n",
    "data_selected_test = data_selected_test.drop(['surface', 'player1_hand','player2_hand'], axis=1)\n",
    "\n",
    "# Reemplazar el guion '-' con una cadena vacía ''\n",
    "data_selected_test['tourney_id'] = data_selected_test['tourney_id'].str.replace('-', '')\n",
    "\n",
    "tourney_level_mapping = {'G': 0, 'M': 1, 'A': 2, 'C': 3, 'S': 4, 'F': 5, 'D': 6}  # Puedes ajustar esto según tus datos\n",
    "data_selected_test['tourney_level_encoded'] = data_selected_test['tourney_level'].map(tourney_level_mapping)\n",
    "\n",
    "# Eliminar la columna original 'tourney_level'\n",
    "data_selected_test = data_selected_test.drop(['tourney_level'], axis=1)\n",
    "\n",
    "winner_entry_mapping = {'WC': 1, 'Q': 2, 'LL': 3, 'PR': 4} \n",
    "data_selected_test['player1_entry_encoded'] = data_selected_test['player1_entry'].map(winner_entry_mapping)\n",
    "data_selected_test['player2_entry_encoded'] = data_selected_test['player2_entry'].map(winner_entry_mapping)\n",
    "\n",
    "# Eliminar la columna original 'player1_entry' y 'player2_entry'\n",
    "data_selected_test = data_selected_test.drop(['player1_entry', 'player2_entry'], axis=1)\n",
    "# Reemplazar NaN con 0 en 'player1_entry_encoded' y 'player2_entry_encoded'\n",
    "data_selected_test['player1_entry_encoded'].fillna(0, inplace=True)\n",
    "data_selected_test['player2_entry_encoded'].fillna(0, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'tourney_id'\n",
    "data_selected_test = data_selected_test.drop(['tourney_id'], axis=1)\n",
    "data_selected_test = data_selected_test.dropna()\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "print(data_selected_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_selected_train['player_id_win']\n",
    "x_train = data_selected_train.drop(['player_id_win'], axis=1)\n",
    "\n",
    "y_test= data_selected_test['player_id_win']\n",
    "x_test = data_selected_test.drop(['player_id_win'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo con datos set2 para redes sequenciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el set de datos siempre gana el player uno, por lo que se podria esperar que la red aprenda este patron, se haran redes de clasificacion binaria, siendo 1 para cuando gana el player 1 y o para cunado gana el player 2 , acontinuacion se presenta el cambio de un porsentaje del set donde se dan vuelta los player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia exacta del DataFrame data_selected y llamarla dataset2\n",
    "dataset2_train = data_selected_train.copy()\n",
    "# Este dataset cumpple la funcion de entrenar un modelo binario de capas densas donde se usa 1 para indicar que gana el player 1 y 0 para indicar que gana el player 2\n",
    "dataset2_train['win'] = 1\n",
    "\n",
    "\n",
    "dataset2_test = data_selected_test.copy()\n",
    "dataset2_test['win'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EN EL SET DE DATOS SIEMPRE GANA EL PLAYER UNO \n",
    "\n",
    "# Establecer una semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tamano_subset = int(0.55 * len(dataset2_train))\n",
    "\n",
    "# Seleccionar al azar un subconjunto de filas para intercambiar las instancias\n",
    "indices_a_cambiar = np.random.choice(dataset2_train.index, size=tamano_subset, replace=False)  # ajusta el tamaño según sea necesario\n",
    "\n",
    "# Copiar las características y etiquetas de Player 1 en dataset2\n",
    "features_player1 = dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]]\n",
    "labels_player1 = 1 - dataset2_train.loc[indices_a_cambiar, 'win']  # Invertir las etiquetas para representar victorias de Player 2\n",
    "\n",
    "# Copiar las características y etiquetas de Player 2 en dataset2\n",
    "features_player2 = dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]]\n",
    "labels_player2 = dataset2_train.loc[indices_a_cambiar, 'win']\n",
    "\n",
    "# Actualizar las instancias de Player 1 en dataset2 con las de Player 2\n",
    "dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]] = features_player2.values\n",
    "dataset2_train.loc[indices_a_cambiar, 'win'] = labels_player2.values  # Invertir las etiquetas en 'win'\n",
    "\n",
    "# Actualizar las instancias de Player 2 en dataset2 con las de Player 1\n",
    "dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]] = features_player1.values\n",
    "dataset2_train.loc[indices_a_cambiar, 'win'] = labels_player1.values\n",
    "\n",
    "# Verificar los primeros registros del DataFrame actualizado (dataset2)\n",
    "#print(dataset2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el mismo trabajo para el dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer una semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tamano_subset = int(0.55 * len(dataset2_test))\n",
    "\n",
    "# Seleccionar al azar un subconjunto de filas para intercambiar las instancias\n",
    "indices_a_cambiar = np.random.choice(dataset2_test.index, size=tamano_subset, replace=False)  # ajusta el tamaño según sea necesario\n",
    "\n",
    "# Copiar las características y etiquetas de Player 1 en dataset2\n",
    "features_player1 = dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]]\n",
    "labels_player1 = 1 - dataset2_test.loc[indices_a_cambiar, 'win']  # Invertir las etiquetas para representar victorias de Player 2\n",
    "\n",
    "# Copiar las características y etiquetas de Player 2 en dataset2\n",
    "features_player2 = dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]]\n",
    "labels_player2 = dataset2_test.loc[indices_a_cambiar, 'win']\n",
    "\n",
    "# Actualizar las instancias de Player 1 en dataset2 con las de Player 2\n",
    "dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]] = features_player2.values\n",
    "dataset2_test.loc[indices_a_cambiar, 'win'] = labels_player2.values  # Invertir las etiquetas en 'win'\n",
    "\n",
    "# Actualizar las instancias de Player 2 en dataset2 con las de Player 1\n",
    "dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]] = features_player1.values\n",
    "dataset2_test.loc[indices_a_cambiar, 'win'] = labels_player1.values\n",
    "\n",
    "# Verificar los primeros registros del DataFrame actualizado (dataset2_test)\n",
    "#print(dataset2_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62327\n",
      "34279\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "print(len(dataset2_train))\n",
    "print(len(dataset2_train[dataset2_train['win'] == 0]))\n",
    "\n",
    "y_dataset2_train = dataset2_train['win']\n",
    "x_dataset2_train = dataset2_train.drop(['player_id_win','win'], axis=1)\n",
    "#y_dataset2_ht= tf.keras.utils.to_categorical(dataset2_train['win'])\n",
    "\n",
    "y_dataset2_test = dataset2_test['win']\n",
    "x_dataset2_test = dataset2_test.drop(['player_id_win','win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset2_test))\n",
    "print(len(dataset2_test[dataset2_test['win'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, n_estimators=130, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=130, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=130, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=130, max_depth=20, random_state=42)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3422090729783038"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model34.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'random_forest_model34.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo secuencial con capas densas y modo de activacion relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "print(YOUR_INPUT_DIM)\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(30, activation=\"relu\", input_dim=YOUR_INPUT_DIM))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(50, activation=\"relu\"))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(20, activation=\"relu\"))\n",
    "model1.add(Dense(units=1, activation='sigmoid'))  \n",
    "model1.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "974/974 [==============================] - 2s 939us/step - loss: 222.5560 - accuracy: 0.5094 - val_loss: 28.5224 - val_accuracy: 0.5498\n",
      "Epoch 2/20\n",
      "974/974 [==============================] - 1s 842us/step - loss: 11.1333 - accuracy: 0.5128 - val_loss: 0.9872 - val_accuracy: 0.4936\n",
      "Epoch 3/20\n",
      "974/974 [==============================] - 1s 846us/step - loss: 4.0222 - accuracy: 0.5107 - val_loss: 5.5903 - val_accuracy: 0.4497\n",
      "Epoch 4/20\n",
      "974/974 [==============================] - 1s 841us/step - loss: 2.0354 - accuracy: 0.5215 - val_loss: 1.4642 - val_accuracy: 0.5577\n",
      "Epoch 5/20\n",
      "974/974 [==============================] - 1s 857us/step - loss: 1.2264 - accuracy: 0.5474 - val_loss: 1.9002 - val_accuracy: 0.4379\n",
      "Epoch 6/20\n",
      "974/974 [==============================] - 1s 853us/step - loss: 0.9417 - accuracy: 0.5763 - val_loss: 1.6433 - val_accuracy: 0.5710\n",
      "Epoch 7/20\n",
      "974/974 [==============================] - 1s 852us/step - loss: 0.8303 - accuracy: 0.5547 - val_loss: 2.7540 - val_accuracy: 0.5247\n",
      "Epoch 8/20\n",
      "974/974 [==============================] - 1s 856us/step - loss: 0.7698 - accuracy: 0.5563 - val_loss: 1.6163 - val_accuracy: 0.5621\n",
      "Epoch 9/20\n",
      "974/974 [==============================] - 1s 860us/step - loss: 0.7443 - accuracy: 0.5528 - val_loss: 1.5404 - val_accuracy: 0.5163\n",
      "Epoch 10/20\n",
      "974/974 [==============================] - 1s 846us/step - loss: 0.7062 - accuracy: 0.5707 - val_loss: 1.1231 - val_accuracy: 0.4975\n",
      "Epoch 11/20\n",
      "974/974 [==============================] - 1s 866us/step - loss: 0.6809 - accuracy: 0.5503 - val_loss: 0.8423 - val_accuracy: 0.5020\n",
      "Epoch 12/20\n",
      "974/974 [==============================] - 1s 839us/step - loss: 0.6909 - accuracy: 0.5565 - val_loss: 1.5858 - val_accuracy: 0.5232\n",
      "Epoch 13/20\n",
      "974/974 [==============================] - 1s 893us/step - loss: 0.6771 - accuracy: 0.5680 - val_loss: 0.6659 - val_accuracy: 0.5641\n",
      "Epoch 14/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.6697 - accuracy: 0.5626 - val_loss: 0.6826 - val_accuracy: 0.5182\n",
      "Epoch 15/20\n",
      "974/974 [==============================] - 1s 858us/step - loss: 0.6610 - accuracy: 0.5892 - val_loss: 0.6617 - val_accuracy: 0.6238\n",
      "Epoch 16/20\n",
      "974/974 [==============================] - 1s 854us/step - loss: 0.6488 - accuracy: 0.6200 - val_loss: 0.6551 - val_accuracy: 0.6070\n",
      "Epoch 17/20\n",
      "974/974 [==============================] - 1s 856us/step - loss: 0.6468 - accuracy: 0.6231 - val_loss: 0.6444 - val_accuracy: 0.6302\n",
      "Epoch 18/20\n",
      "974/974 [==============================] - 1s 848us/step - loss: 0.6463 - accuracy: 0.6222 - val_loss: 0.6495 - val_accuracy: 0.6267\n",
      "Epoch 19/20\n",
      "974/974 [==============================] - 1s 853us/step - loss: 0.6449 - accuracy: 0.6244 - val_loss: 0.6481 - val_accuracy: 0.6203\n",
      "Epoch 20/20\n",
      "974/974 [==============================] - 1s 852us/step - loss: 0.6451 - accuracy: 0.6220 - val_loss: 0.6458 - val_accuracy: 0.6386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f632ae36a70>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_dataset2_train, y_dataset2_train, epochs=20, batch_size=64, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model1.save('keras_model1_relu62.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 636us/step - loss: 0.6458 - accuracy: 0.6386\n",
      "Loss: 0.6458460092544556\n",
      "Accuracy: 0.6385601758956909\n"
     ]
    }
   ],
   "source": [
    "results=model1.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo secuencial de capas densas con activacion LeakyRELU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(70, activation=LeakyReLU(alpha=0.07), input_dim=YOUR_INPUT_DIM))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(25, activation=LeakyReLU(alpha=0.07)))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(30, activation=LeakyReLU(alpha=0.06)))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))  \n",
    "model2.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "974/974 [==============================] - 1s 941us/step - loss: 109.8627 - accuracy: 0.5045 - val_loss: 4.3506 - val_accuracy: 0.5592\n",
      "Epoch 2/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 8.5091 - accuracy: 0.5005 - val_loss: 3.6133 - val_accuracy: 0.4502\n",
      "Epoch 3/50\n",
      "974/974 [==============================] - 1s 857us/step - loss: 3.6961 - accuracy: 0.5057 - val_loss: 2.2885 - val_accuracy: 0.5498\n",
      "Epoch 4/50\n",
      "974/974 [==============================] - 1s 846us/step - loss: 2.2340 - accuracy: 0.5087 - val_loss: 0.9224 - val_accuracy: 0.5498\n",
      "Epoch 5/50\n",
      "974/974 [==============================] - 1s 854us/step - loss: 1.3830 - accuracy: 0.5130 - val_loss: 0.7580 - val_accuracy: 0.5429\n",
      "Epoch 6/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 1.0159 - accuracy: 0.5185 - val_loss: 1.8362 - val_accuracy: 0.5498\n",
      "Epoch 7/50\n",
      "974/974 [==============================] - 1s 852us/step - loss: 0.8937 - accuracy: 0.5330 - val_loss: 1.0707 - val_accuracy: 0.4596\n",
      "Epoch 8/50\n",
      "974/974 [==============================] - 1s 861us/step - loss: 0.7834 - accuracy: 0.5574 - val_loss: 0.7637 - val_accuracy: 0.5005\n",
      "Epoch 9/50\n",
      "974/974 [==============================] - 1s 845us/step - loss: 0.7439 - accuracy: 0.5655 - val_loss: 0.6731 - val_accuracy: 0.5991\n",
      "Epoch 10/50\n",
      "974/974 [==============================] - 1s 847us/step - loss: 0.7003 - accuracy: 0.5880 - val_loss: 0.6779 - val_accuracy: 0.6065\n",
      "Epoch 11/50\n",
      "974/974 [==============================] - 1s 862us/step - loss: 0.7223 - accuracy: 0.5832 - val_loss: 0.7375 - val_accuracy: 0.5962\n",
      "Epoch 12/50\n",
      "974/974 [==============================] - 1s 881us/step - loss: 0.7471 - accuracy: 0.5802 - val_loss: 0.6856 - val_accuracy: 0.6070\n",
      "Epoch 13/50\n",
      "974/974 [==============================] - 1s 845us/step - loss: 0.6970 - accuracy: 0.5987 - val_loss: 0.6748 - val_accuracy: 0.6119\n",
      "Epoch 14/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 0.7198 - accuracy: 0.5887 - val_loss: 0.9648 - val_accuracy: 0.4541\n",
      "Epoch 15/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 0.6855 - accuracy: 0.6059 - val_loss: 1.2383 - val_accuracy: 0.5621\n",
      "Epoch 16/50\n",
      "974/974 [==============================] - 1s 882us/step - loss: 0.6900 - accuracy: 0.5995 - val_loss: 0.8372 - val_accuracy: 0.5611\n",
      "Epoch 17/50\n",
      "974/974 [==============================] - 1s 867us/step - loss: 0.6882 - accuracy: 0.6045 - val_loss: 0.7424 - val_accuracy: 0.6080\n",
      "Epoch 18/50\n",
      "974/974 [==============================] - 1s 854us/step - loss: 0.6877 - accuracy: 0.6020 - val_loss: 1.0843 - val_accuracy: 0.4862\n",
      "Epoch 19/50\n",
      "974/974 [==============================] - 1s 848us/step - loss: 0.6691 - accuracy: 0.6124 - val_loss: 0.7773 - val_accuracy: 0.6065\n",
      "Epoch 20/50\n",
      "974/974 [==============================] - 1s 888us/step - loss: 0.6871 - accuracy: 0.6053 - val_loss: 0.6763 - val_accuracy: 0.6188\n",
      "Epoch 21/50\n",
      "974/974 [==============================] - 1s 881us/step - loss: 0.6693 - accuracy: 0.6155 - val_loss: 0.6600 - val_accuracy: 0.6282\n",
      "Epoch 22/50\n",
      "974/974 [==============================] - 1s 881us/step - loss: 0.6766 - accuracy: 0.6075 - val_loss: 0.7165 - val_accuracy: 0.5695\n",
      "Epoch 23/50\n",
      "974/974 [==============================] - 1s 863us/step - loss: 0.6620 - accuracy: 0.6192 - val_loss: 0.7088 - val_accuracy: 0.5676\n",
      "Epoch 24/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 0.6691 - accuracy: 0.6131 - val_loss: 1.0149 - val_accuracy: 0.4887\n",
      "Epoch 25/50\n",
      "974/974 [==============================] - 1s 882us/step - loss: 0.6561 - accuracy: 0.6200 - val_loss: 0.6867 - val_accuracy: 0.6080\n",
      "Epoch 26/50\n",
      "974/974 [==============================] - 1s 876us/step - loss: 0.6663 - accuracy: 0.6214 - val_loss: 0.8016 - val_accuracy: 0.5715\n",
      "Epoch 27/50\n",
      "974/974 [==============================] - 1s 882us/step - loss: 0.6639 - accuracy: 0.6107 - val_loss: 0.6904 - val_accuracy: 0.5902\n",
      "Epoch 28/50\n",
      "974/974 [==============================] - 1s 861us/step - loss: 0.6595 - accuracy: 0.6181 - val_loss: 0.6429 - val_accuracy: 0.6223\n",
      "Epoch 29/50\n",
      "974/974 [==============================] - 1s 870us/step - loss: 0.6472 - accuracy: 0.6245 - val_loss: 0.6475 - val_accuracy: 0.6302\n",
      "Epoch 30/50\n",
      "974/974 [==============================] - 1s 852us/step - loss: 0.6867 - accuracy: 0.6142 - val_loss: 0.6488 - val_accuracy: 0.6336\n",
      "Epoch 31/50\n",
      "974/974 [==============================] - 1s 873us/step - loss: 0.6452 - accuracy: 0.6266 - val_loss: 0.6472 - val_accuracy: 0.6154\n",
      "Epoch 32/50\n",
      "974/974 [==============================] - 1s 856us/step - loss: 0.6429 - accuracy: 0.6295 - val_loss: 1.2750 - val_accuracy: 0.5922\n",
      "Epoch 33/50\n",
      "974/974 [==============================] - 1s 852us/step - loss: 0.6584 - accuracy: 0.6222 - val_loss: 0.6497 - val_accuracy: 0.6351\n",
      "Epoch 34/50\n",
      "974/974 [==============================] - 1s 861us/step - loss: 0.6391 - accuracy: 0.6341 - val_loss: 0.6600 - val_accuracy: 0.6040\n",
      "Epoch 35/50\n",
      "974/974 [==============================] - 1s 871us/step - loss: 0.6533 - accuracy: 0.6239 - val_loss: 0.6440 - val_accuracy: 0.6395\n",
      "Epoch 36/50\n",
      "974/974 [==============================] - 1s 853us/step - loss: 0.6645 - accuracy: 0.6242 - val_loss: 0.6391 - val_accuracy: 0.6336\n",
      "Epoch 37/50\n",
      "974/974 [==============================] - 1s 860us/step - loss: 0.6414 - accuracy: 0.6302 - val_loss: 0.6502 - val_accuracy: 0.6361\n",
      "Epoch 38/50\n",
      "974/974 [==============================] - 1s 859us/step - loss: 0.6433 - accuracy: 0.6316 - val_loss: 0.6367 - val_accuracy: 0.6376\n",
      "Epoch 39/50\n",
      "974/974 [==============================] - 1s 851us/step - loss: 0.6430 - accuracy: 0.6290 - val_loss: 0.6444 - val_accuracy: 0.6346\n",
      "Epoch 40/50\n",
      "974/974 [==============================] - 1s 846us/step - loss: 0.6512 - accuracy: 0.6256 - val_loss: 0.6500 - val_accuracy: 0.6400\n",
      "Epoch 41/50\n",
      "974/974 [==============================] - 1s 851us/step - loss: 0.6404 - accuracy: 0.6349 - val_loss: 0.7252 - val_accuracy: 0.5814\n",
      "Epoch 42/50\n",
      "974/974 [==============================] - 1s 868us/step - loss: 0.6425 - accuracy: 0.6299 - val_loss: 0.6324 - val_accuracy: 0.6405\n",
      "Epoch 43/50\n",
      "974/974 [==============================] - 1s 854us/step - loss: 0.6375 - accuracy: 0.6353 - val_loss: 0.6608 - val_accuracy: 0.6248\n",
      "Epoch 44/50\n",
      "974/974 [==============================] - 1s 844us/step - loss: 0.6345 - accuracy: 0.6375 - val_loss: 0.6551 - val_accuracy: 0.6001\n",
      "Epoch 45/50\n",
      "974/974 [==============================] - 1s 854us/step - loss: 0.6438 - accuracy: 0.6290 - val_loss: 0.6387 - val_accuracy: 0.6341\n",
      "Epoch 46/50\n",
      "974/974 [==============================] - 1s 835us/step - loss: 0.6349 - accuracy: 0.6384 - val_loss: 0.6876 - val_accuracy: 0.6317\n",
      "Epoch 47/50\n",
      "974/974 [==============================] - 1s 858us/step - loss: 0.6353 - accuracy: 0.6356 - val_loss: 0.6488 - val_accuracy: 0.6243\n",
      "Epoch 48/50\n",
      "974/974 [==============================] - 1s 876us/step - loss: 0.6343 - accuracy: 0.6369 - val_loss: 0.6702 - val_accuracy: 0.5981\n",
      "Epoch 49/50\n",
      "974/974 [==============================] - 1s 866us/step - loss: 0.6341 - accuracy: 0.6359 - val_loss: 0.6394 - val_accuracy: 0.6435\n",
      "Epoch 50/50\n",
      "974/974 [==============================] - 1s 852us/step - loss: 0.6369 - accuracy: 0.6385 - val_loss: 0.6590 - val_accuracy: 0.6223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f62e8895960>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_dataset2_train, y_dataset2_train, epochs=50, batch_size=64, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('keras_model2_leaky63.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 747us/step - loss: 0.6796 - accuracy: 0.6366\n",
      "Loss: 0.6795805096626282\n",
      "Accuracy: 0.6365877985954285\n"
     ]
    }
   ],
   "source": [
    "results=model2.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrenamiento de un tercer modelo secuancial con capas densas y activacion relu y LeakyReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(30, activation=\"relu\", input_dim=YOUR_INPUT_DIM))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(70, activation=LeakyReLU(alpha=0.06)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(50, activation=LeakyReLU(alpha=0.06)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(25, activation=\"relu\"))\n",
    "model3.add(Dense(units=1, activation='sigmoid'))  \n",
    "model3.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "917/917 [==============================] - 2s 1ms/step - loss: 135.3962 - accuracy: 0.5063 - val_loss: 0.9167 - val_accuracy: 0.5108\n",
      "Epoch 2/55\n",
      "917/917 [==============================] - 1s 948us/step - loss: 4.1117 - accuracy: 0.5071 - val_loss: 0.7976 - val_accuracy: 0.5301\n",
      "Epoch 3/55\n",
      "917/917 [==============================] - 1s 934us/step - loss: 1.9344 - accuracy: 0.5084 - val_loss: 0.9444 - val_accuracy: 0.4502\n",
      "Epoch 4/55\n",
      "917/917 [==============================] - 1s 941us/step - loss: 1.2973 - accuracy: 0.5065 - val_loss: 0.8498 - val_accuracy: 0.4502\n",
      "Epoch 5/55\n",
      "917/917 [==============================] - 1s 948us/step - loss: 1.0694 - accuracy: 0.5077 - val_loss: 1.6427 - val_accuracy: 0.5498\n",
      "Epoch 6/55\n",
      "917/917 [==============================] - 1s 955us/step - loss: 0.9441 - accuracy: 0.5096 - val_loss: 0.7142 - val_accuracy: 0.5498\n",
      "Epoch 7/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.8274 - accuracy: 0.5112 - val_loss: 0.8153 - val_accuracy: 0.4502\n",
      "Epoch 8/55\n",
      "917/917 [==============================] - 1s 977us/step - loss: 0.7848 - accuracy: 0.5147 - val_loss: 0.8199 - val_accuracy: 0.5498\n",
      "Epoch 9/55\n",
      "917/917 [==============================] - 1s 955us/step - loss: 0.7564 - accuracy: 0.5263 - val_loss: 0.8354 - val_accuracy: 0.5621\n",
      "Epoch 10/55\n",
      "917/917 [==============================] - 1s 963us/step - loss: 0.7163 - accuracy: 0.5402 - val_loss: 0.6933 - val_accuracy: 0.5483\n",
      "Epoch 11/55\n",
      "917/917 [==============================] - 1s 961us/step - loss: 0.6869 - accuracy: 0.5733 - val_loss: 0.6969 - val_accuracy: 0.6006\n",
      "Epoch 12/55\n",
      "917/917 [==============================] - 1s 942us/step - loss: 0.6701 - accuracy: 0.6050 - val_loss: 0.6710 - val_accuracy: 0.6124\n",
      "Epoch 13/55\n",
      "917/917 [==============================] - 1s 956us/step - loss: 0.6620 - accuracy: 0.6121 - val_loss: 0.6893 - val_accuracy: 0.5922\n",
      "Epoch 14/55\n",
      "917/917 [==============================] - 1s 947us/step - loss: 0.6498 - accuracy: 0.6266 - val_loss: 0.6665 - val_accuracy: 0.6129\n",
      "Epoch 15/55\n",
      "917/917 [==============================] - 1s 995us/step - loss: 0.6475 - accuracy: 0.6274 - val_loss: 0.6835 - val_accuracy: 0.6193\n",
      "Epoch 16/55\n",
      "917/917 [==============================] - 1s 979us/step - loss: 0.6454 - accuracy: 0.6281 - val_loss: 0.6490 - val_accuracy: 0.5981\n",
      "Epoch 17/55\n",
      "917/917 [==============================] - 1s 952us/step - loss: 0.6446 - accuracy: 0.6275 - val_loss: 0.6458 - val_accuracy: 0.6336\n",
      "Epoch 18/55\n",
      "917/917 [==============================] - 1s 961us/step - loss: 0.6438 - accuracy: 0.6291 - val_loss: 0.6457 - val_accuracy: 0.6257\n",
      "Epoch 19/55\n",
      "917/917 [==============================] - 1s 953us/step - loss: 0.6441 - accuracy: 0.6287 - val_loss: 0.6456 - val_accuracy: 0.6233\n",
      "Epoch 20/55\n",
      "917/917 [==============================] - 1s 946us/step - loss: 0.6445 - accuracy: 0.6285 - val_loss: 0.6397 - val_accuracy: 0.6307\n",
      "Epoch 21/55\n",
      "917/917 [==============================] - 1s 957us/step - loss: 0.6463 - accuracy: 0.6254 - val_loss: 0.6535 - val_accuracy: 0.6297\n",
      "Epoch 22/55\n",
      "917/917 [==============================] - 1s 957us/step - loss: 0.6434 - accuracy: 0.6317 - val_loss: 0.6462 - val_accuracy: 0.6159\n",
      "Epoch 23/55\n",
      "917/917 [==============================] - 1s 988us/step - loss: 0.6433 - accuracy: 0.6280 - val_loss: 0.6583 - val_accuracy: 0.6188\n",
      "Epoch 24/55\n",
      "917/917 [==============================] - 1s 981us/step - loss: 0.6407 - accuracy: 0.6317 - val_loss: 0.6495 - val_accuracy: 0.6026\n",
      "Epoch 25/55\n",
      "917/917 [==============================] - 1s 952us/step - loss: 0.6418 - accuracy: 0.6325 - val_loss: 0.6432 - val_accuracy: 0.6228\n",
      "Epoch 26/55\n",
      "917/917 [==============================] - 1s 983us/step - loss: 0.6410 - accuracy: 0.6315 - val_loss: 0.6389 - val_accuracy: 0.6257\n",
      "Epoch 27/55\n",
      "917/917 [==============================] - 1s 968us/step - loss: 0.6441 - accuracy: 0.6269 - val_loss: 0.6416 - val_accuracy: 0.6213\n",
      "Epoch 28/55\n",
      "917/917 [==============================] - 1s 949us/step - loss: 0.6394 - accuracy: 0.6352 - val_loss: 0.6398 - val_accuracy: 0.6297\n",
      "Epoch 29/55\n",
      "917/917 [==============================] - 1s 948us/step - loss: 0.6417 - accuracy: 0.6334 - val_loss: 0.6428 - val_accuracy: 0.6252\n",
      "Epoch 30/55\n",
      "917/917 [==============================] - 1s 973us/step - loss: 0.6431 - accuracy: 0.6295 - val_loss: 0.6459 - val_accuracy: 0.6287\n",
      "Epoch 31/55\n",
      "917/917 [==============================] - 1s 940us/step - loss: 0.6428 - accuracy: 0.6291 - val_loss: 0.6396 - val_accuracy: 0.6321\n",
      "Epoch 32/55\n",
      "917/917 [==============================] - 1s 947us/step - loss: 0.6398 - accuracy: 0.6331 - val_loss: 0.6402 - val_accuracy: 0.6312\n",
      "Epoch 33/55\n",
      "917/917 [==============================] - 1s 947us/step - loss: 0.6407 - accuracy: 0.6338 - val_loss: 0.6453 - val_accuracy: 0.6326\n",
      "Epoch 34/55\n",
      "917/917 [==============================] - 1s 948us/step - loss: 0.6409 - accuracy: 0.6322 - val_loss: 0.6399 - val_accuracy: 0.6356\n",
      "Epoch 35/55\n",
      "917/917 [==============================] - 1s 962us/step - loss: 0.6387 - accuracy: 0.6346 - val_loss: 0.6424 - val_accuracy: 0.6331\n",
      "Epoch 36/55\n",
      "917/917 [==============================] - 1s 956us/step - loss: 0.6378 - accuracy: 0.6367 - val_loss: 0.6396 - val_accuracy: 0.6331\n",
      "Epoch 37/55\n",
      "917/917 [==============================] - 1s 948us/step - loss: 0.6380 - accuracy: 0.6376 - val_loss: 0.6408 - val_accuracy: 0.6346\n",
      "Epoch 38/55\n",
      "917/917 [==============================] - 1s 957us/step - loss: 0.6389 - accuracy: 0.6343 - val_loss: 0.6459 - val_accuracy: 0.6302\n",
      "Epoch 39/55\n",
      "917/917 [==============================] - 1s 959us/step - loss: 0.6369 - accuracy: 0.6399 - val_loss: 0.6391 - val_accuracy: 0.6361\n",
      "Epoch 40/55\n",
      "917/917 [==============================] - 1s 955us/step - loss: 0.6356 - accuracy: 0.6416 - val_loss: 0.6434 - val_accuracy: 0.6331\n",
      "Epoch 41/55\n",
      "917/917 [==============================] - 1s 960us/step - loss: 0.6362 - accuracy: 0.6399 - val_loss: 0.6393 - val_accuracy: 0.6391\n",
      "Epoch 42/55\n",
      "917/917 [==============================] - 1s 957us/step - loss: 0.6345 - accuracy: 0.6411 - val_loss: 0.6410 - val_accuracy: 0.6243\n",
      "Epoch 43/55\n",
      "917/917 [==============================] - 1s 949us/step - loss: 0.6362 - accuracy: 0.6394 - val_loss: 0.6430 - val_accuracy: 0.6376\n",
      "Epoch 44/55\n",
      "917/917 [==============================] - 1s 971us/step - loss: 0.6349 - accuracy: 0.6421 - val_loss: 0.6383 - val_accuracy: 0.6297\n",
      "Epoch 45/55\n",
      "917/917 [==============================] - 1s 932us/step - loss: 0.6350 - accuracy: 0.6399 - val_loss: 0.6418 - val_accuracy: 0.6400\n",
      "Epoch 46/55\n",
      "917/917 [==============================] - 1s 952us/step - loss: 0.6364 - accuracy: 0.6394 - val_loss: 0.6457 - val_accuracy: 0.6292\n",
      "Epoch 47/55\n",
      "917/917 [==============================] - 1s 963us/step - loss: 0.6347 - accuracy: 0.6414 - val_loss: 0.6414 - val_accuracy: 0.6415\n",
      "Epoch 48/55\n",
      "917/917 [==============================] - 1s 944us/step - loss: 0.6351 - accuracy: 0.6428 - val_loss: 0.6464 - val_accuracy: 0.6302\n",
      "Epoch 49/55\n",
      "917/917 [==============================] - 1s 943us/step - loss: 0.6346 - accuracy: 0.6410 - val_loss: 0.6396 - val_accuracy: 0.6376\n",
      "Epoch 50/55\n",
      "917/917 [==============================] - 1s 942us/step - loss: 0.6349 - accuracy: 0.6395 - val_loss: 0.6421 - val_accuracy: 0.6326\n",
      "Epoch 51/55\n",
      "917/917 [==============================] - 1s 976us/step - loss: 0.6340 - accuracy: 0.6407 - val_loss: 0.6386 - val_accuracy: 0.6321\n",
      "Epoch 52/55\n",
      "917/917 [==============================] - 1s 944us/step - loss: 0.6341 - accuracy: 0.6414 - val_loss: 0.6410 - val_accuracy: 0.6351\n",
      "Epoch 53/55\n",
      "917/917 [==============================] - 1s 956us/step - loss: 0.6335 - accuracy: 0.6421 - val_loss: 0.6456 - val_accuracy: 0.6287\n",
      "Epoch 54/55\n",
      "917/917 [==============================] - 1s 941us/step - loss: 0.6350 - accuracy: 0.6406 - val_loss: 0.6379 - val_accuracy: 0.6336\n",
      "Epoch 55/55\n",
      "917/917 [==============================] - 1s 953us/step - loss: 0.6336 - accuracy: 0.6445 - val_loss: 0.6389 - val_accuracy: 0.6326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f62af5586d0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_dataset2_train, y_dataset2_train, epochs=55, batch_size=68, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model3.save('keras_model3_64_relu_leaky.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 659us/step - loss: 0.6389 - accuracy: 0.6326\n",
      "Loss: 0.6388853192329407\n",
      "Accuracy: 0.6326429843902588\n"
     ]
    }
   ],
   "source": [
    "results=model3.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
