{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo con datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECCION DATOS DE ENTRENAMIENTO Y TEST , 2023 SE USARAN PARA TEST\n",
    "data_train = pd.read_csv('atp_matches_2000.csv')\n",
    "data_test=pd.read_csv('atp_matches_2023.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the data from 2001 to 2022\n",
    "for i in range(1, 22):\n",
    "    data_train = pd.concat([data_train, pd.read_csv('atp_matches_20' + str(i).zfill(2) + '.csv')])\n",
    "data_train.index = range(0,len(data_train)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player1_id', 'player1_ht', 'player1_age', 'player2_id', 'player2_ht',\n",
      "       'player2_age', 'player1_rank_points', 'player2_rank_points',\n",
      "       'player_id_win', 'surface_encoded', 'player1_hand_encoded',\n",
      "       'player2_hand_encoded', 'tourney_level_encoded',\n",
      "       'player1_entry_encoded', 'player2_entry_encoded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32369/2256230725.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected_train['player_id_win'] = data_selected_train['winner_id']\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las columnas deseadas\n",
    "selected_columns = ['tourney_id', 'surface', 'tourney_level', 'winner_id', 'winner_entry', 'winner_hand', 'winner_ht', 'winner_age', 'loser_id', 'loser_entry', 'loser_hand', 'loser_ht', 'loser_age', 'winner_rank_points', 'loser_rank_points']\n",
    "\n",
    "# Se crea un dataframe con las columnas seleccionadas\n",
    "data_selected_train = data_train[selected_columns]\n",
    "\n",
    "# Crear una nueva columna llamadaplayer_id_win\n",
    "data_selected_train['player_id_win'] = data_selected_train['winner_id']\n",
    "\n",
    "\n",
    "data_selected_train = data_selected_train.rename(columns={\n",
    "    'winner_id': 'player1_id',\n",
    "    'winner_entry': 'player1_entry',\n",
    "    'winner_hand': 'player1_hand',\n",
    "    'winner_ht': 'player1_ht',\n",
    "    'winner_age': 'player1_age',\n",
    "    'winner_rank_points': 'player1_rank_points',\n",
    "    'loser_id': 'player2_id',\n",
    "    'loser_entry': 'player2_entry',\n",
    "    'loser_hand': 'player2_hand',\n",
    "    'loser_ht': 'player2_ht',\n",
    "    'loser_age': 'player2_age',\n",
    "    'loser_rank_points': 'player2_rank_points'\n",
    "})\n",
    "# Mapeo para 'surface'\n",
    "surface_mapping = {'Clay': 0, 'Grass': 1, 'Hard': 2, 'Carpet': 3} \n",
    "data_selected_train['surface_encoded'] = data_selected_train['surface'].map(surface_mapping)\n",
    "\n",
    "# Mapeo para 'winner_hand'\n",
    "hand_mapping = {'R': 0, 'L': 1, 'U': 2}  # Puedes ajustar esto según tus datos\n",
    "data_selected_train['player1_hand_encoded'] = data_selected_train['player1_hand'].map(hand_mapping)\n",
    "data_selected_train['player2_hand_encoded'] = data_selected_train['player2_hand'].map(hand_mapping)\n",
    "data_selected_train = data_selected_train.drop(['surface', 'player1_hand','player2_hand'], axis=1)\n",
    "\n",
    "# Reemplazar el guion '-' con una cadena vacía ''\n",
    "data_selected_train['tourney_id'] = data_selected_train['tourney_id'].str.replace('-', '')\n",
    "\n",
    "\n",
    "tourney_level_mapping = {'G': 0, 'M': 1, 'A': 2, 'C': 3, 'S': 4, 'F': 5, 'D': 6}  # Puedes ajustar esto según tus datos\n",
    "data_selected_train['tourney_level_encoded'] = data_selected_train['tourney_level'].map(tourney_level_mapping)\n",
    "\n",
    "# Eliminar la columna original 'tourney_level'\n",
    "data_selected_train = data_selected_train.drop(['tourney_level'], axis=1)\n",
    "\n",
    "winner_entry_mapping = {'WC': 1, 'Q': 2, 'LL': 3, 'PR': 4} \n",
    "data_selected_train['player1_entry_encoded'] = data_selected_train['player1_entry'].map(winner_entry_mapping)\n",
    "data_selected_train['player2_entry_encoded'] = data_selected_train['player2_entry'].map(winner_entry_mapping)\n",
    "\n",
    "# Eliminar la columna original 'player1_entry' y 'player2_entry'\n",
    "data_selected_train = data_selected_train.drop(['player1_entry', 'player2_entry'], axis=1)\n",
    "# Reemplazar NaN con 0 en 'player1_entry_encoded' y 'player2_entry_encoded'\n",
    "data_selected_train['player1_entry_encoded'].fillna(0, inplace=True)\n",
    "data_selected_train['player2_entry_encoded'].fillna(0, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'tourney_id'\n",
    "data_selected_train = data_selected_train.drop(['tourney_id'], axis=1)\n",
    "data_selected_train = data_selected_train.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "#print(data_selected.head())\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "print(data_selected_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player1_id', 'player1_ht', 'player1_age', 'player2_id', 'player2_ht',\n",
      "       'player2_age', 'player1_rank_points', 'player2_rank_points',\n",
      "       'player_id_win', 'surface_encoded', 'player1_hand_encoded',\n",
      "       'player2_hand_encoded', 'tourney_level_encoded',\n",
      "       'player1_entry_encoded', 'player2_entry_encoded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32369/294209450.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected_test['player_id_win'] = data_selected_test['winner_id']\n"
     ]
    }
   ],
   "source": [
    "# Se crea un dataframe con las columnas seleccionadas\n",
    "data_selected_test = data_test[selected_columns]\n",
    "\n",
    "# Crear una nueva columna llamada player_id_win\n",
    "data_selected_test['player_id_win'] = data_selected_test['winner_id']\n",
    "\n",
    "data_selected_test = data_selected_test.rename(columns={\n",
    "    'winner_id': 'player1_id',\n",
    "    'winner_entry': 'player1_entry',\n",
    "    'winner_hand': 'player1_hand',\n",
    "    'winner_ht': 'player1_ht',\n",
    "    'winner_age': 'player1_age',\n",
    "    'winner_rank_points': 'player1_rank_points',\n",
    "    'loser_id': 'player2_id',\n",
    "    'loser_entry': 'player2_entry',\n",
    "    'loser_hand': 'player2_hand',\n",
    "    'loser_ht': 'player2_ht',\n",
    "    'loser_age': 'player2_age',\n",
    "    'loser_rank_points': 'player2_rank_points'\n",
    "})\n",
    "# Mapeo para 'surface'\n",
    "surface_mapping = {'Clay': 0, 'Grass': 1, 'Hard': 2, 'Carpet': 3} \n",
    "data_selected_test['surface_encoded'] = data_selected_test['surface'].map(surface_mapping)\n",
    "\n",
    "# Mapeo para 'winner_hand'\n",
    "hand_mapping = {'R': 0, 'L': 1, 'U': 2}  # Puedes ajustar esto según tus datos\n",
    "data_selected_test['player1_hand_encoded'] = data_selected_test['player1_hand'].map(hand_mapping)\n",
    "data_selected_test['player2_hand_encoded'] = data_selected_test['player2_hand'].map(hand_mapping)\n",
    "data_selected_test = data_selected_test.drop(['surface', 'player1_hand','player2_hand'], axis=1)\n",
    "\n",
    "# Reemplazar el guion '-' con una cadena vacía ''\n",
    "data_selected_test['tourney_id'] = data_selected_test['tourney_id'].str.replace('-', '')\n",
    "\n",
    "tourney_level_mapping = {'G': 0, 'M': 1, 'A': 2, 'C': 3, 'S': 4, 'F': 5, 'D': 6}  # Puedes ajustar esto según tus datos\n",
    "data_selected_test['tourney_level_encoded'] = data_selected_test['tourney_level'].map(tourney_level_mapping)\n",
    "\n",
    "# Eliminar la columna original 'tourney_level'\n",
    "data_selected_test = data_selected_test.drop(['tourney_level'], axis=1)\n",
    "\n",
    "winner_entry_mapping = {'WC': 1, 'Q': 2, 'LL': 3, 'PR': 4} \n",
    "data_selected_test['player1_entry_encoded'] = data_selected_test['player1_entry'].map(winner_entry_mapping)\n",
    "data_selected_test['player2_entry_encoded'] = data_selected_test['player2_entry'].map(winner_entry_mapping)\n",
    "\n",
    "# Eliminar la columna original 'player1_entry' y 'player2_entry'\n",
    "data_selected_test = data_selected_test.drop(['player1_entry', 'player2_entry'], axis=1)\n",
    "# Reemplazar NaN con 0 en 'player1_entry_encoded' y 'player2_entry_encoded'\n",
    "data_selected_test['player1_entry_encoded'].fillna(0, inplace=True)\n",
    "data_selected_test['player2_entry_encoded'].fillna(0, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'tourney_id'\n",
    "data_selected_test = data_selected_test.drop(['tourney_id'], axis=1)\n",
    "data_selected_test = data_selected_test.dropna()\n",
    "\n",
    "# Visualizar las primeras filas del DataFrame actualizado\n",
    "print(data_selected_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_selected_train['player_id_win']\n",
    "x_train = data_selected_train.drop(['player_id_win'], axis=1)\n",
    "\n",
    "y_test= data_selected_test['player_id_win']\n",
    "x_test = data_selected_test.drop(['player_id_win'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo con datos set2 para redes sequenciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el set de datos siempre gana el player uno, por lo que se podria esperar que la red aprenda este patron, se haran redes de clasificacion binaria, siendo 1 para cuando gana el player 1 y o para cunado gana el player 2 , acontinuacion se presenta el cambio de un porsentaje del set donde se dan vuelta los player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia exacta del DataFrame data_selected y llamarla dataset2\n",
    "dataset2_train = data_selected_train.copy()\n",
    "# Este dataset cumpple la funcion de entrenar un modelo binario de capas densas donde se usa 1 para indicar que gana el player 1 y 0 para indicar que gana el player 2\n",
    "dataset2_train['win'] = 1\n",
    "\n",
    "\n",
    "dataset2_test = data_selected_test.copy()\n",
    "dataset2_test['win'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EN EL SET DE DATOS SIEMPRE GANA EL PLAYER UNO \n",
    "\n",
    "# Establecer una semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tamano_subset = int(0.55 * len(dataset2_train))\n",
    "\n",
    "# Seleccionar al azar un subconjunto de filas para intercambiar las instancias\n",
    "indices_a_cambiar = np.random.choice(dataset2_train.index, size=tamano_subset, replace=False)  # ajusta el tamaño según sea necesario\n",
    "\n",
    "# Copiar las características y etiquetas de Player 1 en dataset2\n",
    "features_player1 = dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]]\n",
    "labels_player1 = 1 - dataset2_train.loc[indices_a_cambiar, 'win']  # Invertir las etiquetas para representar victorias de Player 2\n",
    "\n",
    "# Copiar las características y etiquetas de Player 2 en dataset2\n",
    "features_player2 = dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]]\n",
    "labels_player2 = dataset2_train.loc[indices_a_cambiar, 'win']\n",
    "\n",
    "# Actualizar las instancias de Player 1 en dataset2 con las de Player 2\n",
    "dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]] = features_player2.values\n",
    "dataset2_train.loc[indices_a_cambiar, 'win'] = labels_player2.values  # Invertir las etiquetas en 'win'\n",
    "\n",
    "# Actualizar las instancias de Player 2 en dataset2 con las de Player 1\n",
    "dataset2_train.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]] = features_player1.values\n",
    "dataset2_train.loc[indices_a_cambiar, 'win'] = labels_player1.values\n",
    "\n",
    "# Verificar los primeros registros del DataFrame actualizado (dataset2)\n",
    "#print(dataset2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el mismo trabajo para el dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer una semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tamano_subset = int(0.55 * len(dataset2_test))\n",
    "\n",
    "# Seleccionar al azar un subconjunto de filas para intercambiar las instancias\n",
    "indices_a_cambiar = np.random.choice(dataset2_test.index, size=tamano_subset, replace=False)  # ajusta el tamaño según sea necesario\n",
    "\n",
    "# Copiar las características y etiquetas de Player 1 en dataset2\n",
    "features_player1 = dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]]\n",
    "labels_player1 = 1 - dataset2_test.loc[indices_a_cambiar, 'win']  # Invertir las etiquetas para representar victorias de Player 2\n",
    "\n",
    "# Copiar las características y etiquetas de Player 2 en dataset2\n",
    "features_player2 = dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]]\n",
    "labels_player2 = dataset2_test.loc[indices_a_cambiar, 'win']\n",
    "\n",
    "# Actualizar las instancias de Player 1 en dataset2 con las de Player 2\n",
    "dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player1_id', 'player1_ht', 'player1_age', 'player1_rank_points',\n",
    "    'player1_hand_encoded', 'player1_entry_encoded'\n",
    "]] = features_player2.values\n",
    "dataset2_test.loc[indices_a_cambiar, 'win'] = labels_player2.values  # Invertir las etiquetas en 'win'\n",
    "\n",
    "# Actualizar las instancias de Player 2 en dataset2 con las de Player 1\n",
    "dataset2_test.loc[indices_a_cambiar, [\n",
    "    'player2_id', 'player2_ht', 'player2_age', 'player2_rank_points',\n",
    "    'player2_hand_encoded', 'player2_entry_encoded'\n",
    "]] = features_player1.values\n",
    "dataset2_test.loc[indices_a_cambiar, 'win'] = labels_player1.values\n",
    "\n",
    "# Verificar los primeros registros del DataFrame actualizado (dataset2_test)\n",
    "#print(dataset2_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62327\n",
      "34279\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "print(len(dataset2_train))\n",
    "print(len(dataset2_train[dataset2_train['win'] == 0]))\n",
    "\n",
    "y_dataset2_train = dataset2_train['win']\n",
    "x_dataset2_train = dataset2_train.drop(['player_id_win','win'], axis=1)\n",
    "#y_dataset2_ht= tf.keras.utils.to_categorical(dataset2_train['win'])\n",
    "\n",
    "y_dataset2_test = dataset2_test['win']\n",
    "x_dataset2_test = dataset2_test.drop(['player_id_win','win'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028\n",
      "1115\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset2_test))\n",
    "print(len(dataset2_test[dataset2_test['win'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, n_estimators=130, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=130, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=130, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=130, max_depth=20, random_state=42)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3422090729783038"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/random_forest_model34.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'models/random_forest_model34.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo secuencial con capas densas y modo de activacion relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 18:47:36.758366: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-30 18:47:36.896261: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 18:47:36.896303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 18:47:36.921496: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 18:47:36.974483: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-30 18:47:36.976150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-30 18:47:37.809650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 18:47:40.442048: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-30 18:47:40.443073: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "print(YOUR_INPUT_DIM)\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(30, activation=\"relu\", input_dim=YOUR_INPUT_DIM))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(50, activation=\"relu\"))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(20, activation=\"relu\"))\n",
    "model1.add(Dense(units=1, activation='sigmoid'))  \n",
    "model1.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "974/974 [==============================] - 2s 977us/step - loss: 165.0991 - accuracy: 0.5062 - val_loss: 5.8462 - val_accuracy: 0.5498\n",
      "Epoch 2/20\n",
      "974/974 [==============================] - 1s 910us/step - loss: 8.1962 - accuracy: 0.5045 - val_loss: 2.3111 - val_accuracy: 0.5498\n",
      "Epoch 3/20\n",
      "974/974 [==============================] - 1s 802us/step - loss: 2.2203 - accuracy: 0.5092 - val_loss: 1.4975 - val_accuracy: 0.4502\n",
      "Epoch 4/20\n",
      "974/974 [==============================] - 1s 799us/step - loss: 1.1758 - accuracy: 0.5113 - val_loss: 1.2748 - val_accuracy: 0.4502\n",
      "Epoch 5/20\n",
      "974/974 [==============================] - 1s 815us/step - loss: 0.8789 - accuracy: 0.5105 - val_loss: 0.7819 - val_accuracy: 0.5498\n",
      "Epoch 6/20\n",
      "974/974 [==============================] - 1s 797us/step - loss: 0.8120 - accuracy: 0.5261 - val_loss: 0.9375 - val_accuracy: 0.5498\n",
      "Epoch 7/20\n",
      "974/974 [==============================] - 1s 810us/step - loss: 0.7446 - accuracy: 0.5360 - val_loss: 0.7275 - val_accuracy: 0.4433\n",
      "Epoch 8/20\n",
      "974/974 [==============================] - 1s 1ms/step - loss: 0.7103 - accuracy: 0.5444 - val_loss: 0.6884 - val_accuracy: 0.5498\n",
      "Epoch 9/20\n",
      "974/974 [==============================] - 1s 863us/step - loss: 0.7298 - accuracy: 0.5460 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 10/20\n",
      "974/974 [==============================] - 1s 832us/step - loss: 0.7018 - accuracy: 0.5478 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 11/20\n",
      "974/974 [==============================] - 1s 844us/step - loss: 0.7042 - accuracy: 0.5491 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 12/20\n",
      "974/974 [==============================] - 1s 825us/step - loss: 0.7039 - accuracy: 0.5492 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 13/20\n",
      "974/974 [==============================] - 1s 874us/step - loss: 0.6973 - accuracy: 0.5496 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 14/20\n",
      "974/974 [==============================] - 1s 926us/step - loss: 0.6923 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 15/20\n",
      "974/974 [==============================] - 1s 850us/step - loss: 0.6913 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 16/20\n",
      "974/974 [==============================] - 1s 840us/step - loss: 0.6994 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 17/20\n",
      "974/974 [==============================] - 1s 864us/step - loss: 0.6932 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 18/20\n",
      "974/974 [==============================] - 1s 822us/step - loss: 0.6904 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 19/20\n",
      "974/974 [==============================] - 1s 844us/step - loss: 0.6893 - accuracy: 0.5500 - val_loss: 0.6883 - val_accuracy: 0.5498\n",
      "Epoch 20/20\n",
      "974/974 [==============================] - 1s 837us/step - loss: 0.6886 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb34281f730>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_dataset2_train, y_dataset2_train, epochs=20, batch_size=64, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.save('models/keras_model1_relu62.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/64 [..............................] - ETA: 0s - loss: 0.6980 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 919us/step - loss: 0.6882 - accuracy: 0.5498\n",
      "Loss: 0.6881791353225708\n",
      "Accuracy: 0.5498027801513672\n"
     ]
    }
   ],
   "source": [
    "results=model1.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de un modelo secuencial de capas densas con activacion LeakyRELU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(70, activation=LeakyReLU(alpha=0.07), input_dim=YOUR_INPUT_DIM))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(25, activation=LeakyReLU(alpha=0.07)))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(30, activation=LeakyReLU(alpha=0.06)))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))  \n",
    "model2.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "974/974 [==============================] - 1s 909us/step - loss: 424.1338 - accuracy: 0.5064 - val_loss: 32.3649 - val_accuracy: 0.4502\n",
      "Epoch 2/50\n",
      "974/974 [==============================] - 1s 828us/step - loss: 29.9921 - accuracy: 0.5073 - val_loss: 9.1060 - val_accuracy: 0.5498\n",
      "Epoch 3/50\n",
      "974/974 [==============================] - 1s 811us/step - loss: 13.4382 - accuracy: 0.5105 - val_loss: 1.7915 - val_accuracy: 0.5498\n",
      "Epoch 4/50\n",
      "974/974 [==============================] - 1s 827us/step - loss: 6.5754 - accuracy: 0.5052 - val_loss: 4.1532 - val_accuracy: 0.5498\n",
      "Epoch 5/50\n",
      "974/974 [==============================] - 1s 814us/step - loss: 3.0014 - accuracy: 0.5190 - val_loss: 0.8477 - val_accuracy: 0.5537\n",
      "Epoch 6/50\n",
      "974/974 [==============================] - 1s 807us/step - loss: 1.7418 - accuracy: 0.5218 - val_loss: 1.2046 - val_accuracy: 0.5498\n",
      "Epoch 7/50\n",
      "974/974 [==============================] - 1s 858us/step - loss: 1.1514 - accuracy: 0.5232 - val_loss: 0.7462 - val_accuracy: 0.5227\n",
      "Epoch 8/50\n",
      "974/974 [==============================] - 1s 825us/step - loss: 0.9590 - accuracy: 0.5290 - val_loss: 1.3846 - val_accuracy: 0.5498\n",
      "Epoch 9/50\n",
      "974/974 [==============================] - 1s 854us/step - loss: 0.8801 - accuracy: 0.5315 - val_loss: 0.6770 - val_accuracy: 0.5478\n",
      "Epoch 10/50\n",
      "974/974 [==============================] - 1s 827us/step - loss: 0.8777 - accuracy: 0.5371 - val_loss: 0.6894 - val_accuracy: 0.5868\n",
      "Epoch 11/50\n",
      "974/974 [==============================] - 1s 866us/step - loss: 0.8309 - accuracy: 0.5443 - val_loss: 1.4675 - val_accuracy: 0.5547\n",
      "Epoch 12/50\n",
      "974/974 [==============================] - 1s 886us/step - loss: 0.8011 - accuracy: 0.5471 - val_loss: 1.5605 - val_accuracy: 0.5513\n",
      "Epoch 13/50\n",
      "974/974 [==============================] - 1s 813us/step - loss: 0.7884 - accuracy: 0.5561 - val_loss: 0.7398 - val_accuracy: 0.5745\n",
      "Epoch 14/50\n",
      "974/974 [==============================] - 1s 844us/step - loss: 0.7799 - accuracy: 0.5595 - val_loss: 0.6824 - val_accuracy: 0.6129\n",
      "Epoch 15/50\n",
      "974/974 [==============================] - 1s 841us/step - loss: 0.7678 - accuracy: 0.5636 - val_loss: 0.6494 - val_accuracy: 0.6154\n",
      "Epoch 16/50\n",
      "974/974 [==============================] - 1s 815us/step - loss: 0.7922 - accuracy: 0.5698 - val_loss: 0.6946 - val_accuracy: 0.6159\n",
      "Epoch 17/50\n",
      "974/974 [==============================] - 1s 814us/step - loss: 0.7189 - accuracy: 0.5733 - val_loss: 0.6538 - val_accuracy: 0.6307\n",
      "Epoch 18/50\n",
      "974/974 [==============================] - 1s 835us/step - loss: 0.6979 - accuracy: 0.5852 - val_loss: 0.8287 - val_accuracy: 0.5370\n",
      "Epoch 19/50\n",
      "974/974 [==============================] - 1s 878us/step - loss: 0.7308 - accuracy: 0.5808 - val_loss: 0.7362 - val_accuracy: 0.5656\n",
      "Epoch 20/50\n",
      "974/974 [==============================] - 1s 865us/step - loss: 0.7060 - accuracy: 0.5851 - val_loss: 0.6494 - val_accuracy: 0.6326\n",
      "Epoch 21/50\n",
      "974/974 [==============================] - 1s 893us/step - loss: 0.6833 - accuracy: 0.5948 - val_loss: 0.7130 - val_accuracy: 0.5542\n",
      "Epoch 22/50\n",
      "974/974 [==============================] - 1s 868us/step - loss: 0.6841 - accuracy: 0.5991 - val_loss: 1.1157 - val_accuracy: 0.5434\n",
      "Epoch 23/50\n",
      "974/974 [==============================] - 1s 871us/step - loss: 0.6909 - accuracy: 0.5934 - val_loss: 0.6661 - val_accuracy: 0.5759\n",
      "Epoch 24/50\n",
      "974/974 [==============================] - 1s 848us/step - loss: 0.6702 - accuracy: 0.6048 - val_loss: 0.6556 - val_accuracy: 0.5986\n",
      "Epoch 25/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 0.6864 - accuracy: 0.6033 - val_loss: 0.7154 - val_accuracy: 0.5750\n",
      "Epoch 26/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 0.6568 - accuracy: 0.6156 - val_loss: 0.6361 - val_accuracy: 0.6464\n",
      "Epoch 27/50\n",
      "974/974 [==============================] - 1s 848us/step - loss: 0.6737 - accuracy: 0.6040 - val_loss: 0.8299 - val_accuracy: 0.6031\n",
      "Epoch 28/50\n",
      "974/974 [==============================] - 1s 862us/step - loss: 0.6599 - accuracy: 0.6155 - val_loss: 0.6362 - val_accuracy: 0.6307\n",
      "Epoch 29/50\n",
      "974/974 [==============================] - 1s 869us/step - loss: 0.6642 - accuracy: 0.6146 - val_loss: 0.6511 - val_accuracy: 0.5917\n",
      "Epoch 30/50\n",
      "974/974 [==============================] - 1s 841us/step - loss: 0.6600 - accuracy: 0.6139 - val_loss: 0.7321 - val_accuracy: 0.5863\n",
      "Epoch 31/50\n",
      "974/974 [==============================] - 1s 847us/step - loss: 0.6594 - accuracy: 0.6162 - val_loss: 0.6684 - val_accuracy: 0.6154\n",
      "Epoch 32/50\n",
      "974/974 [==============================] - 1s 864us/step - loss: 0.6803 - accuracy: 0.6094 - val_loss: 0.7582 - val_accuracy: 0.5833\n",
      "Epoch 33/50\n",
      "974/974 [==============================] - 1s 873us/step - loss: 0.6747 - accuracy: 0.6106 - val_loss: 0.6508 - val_accuracy: 0.6129\n",
      "Epoch 34/50\n",
      "974/974 [==============================] - 1s 852us/step - loss: 0.6388 - accuracy: 0.6321 - val_loss: 0.6451 - val_accuracy: 0.6095\n",
      "Epoch 35/50\n",
      "974/974 [==============================] - 1s 833us/step - loss: 0.6410 - accuracy: 0.6305 - val_loss: 0.6586 - val_accuracy: 0.6272\n",
      "Epoch 36/50\n",
      "974/974 [==============================] - 1s 849us/step - loss: 0.6564 - accuracy: 0.6160 - val_loss: 0.7627 - val_accuracy: 0.5774\n",
      "Epoch 37/50\n",
      "974/974 [==============================] - 1s 865us/step - loss: 0.6576 - accuracy: 0.6169 - val_loss: 0.6535 - val_accuracy: 0.6026\n",
      "Epoch 38/50\n",
      "974/974 [==============================] - 1s 840us/step - loss: 0.6548 - accuracy: 0.6165 - val_loss: 0.6410 - val_accuracy: 0.6317\n",
      "Epoch 39/50\n",
      "974/974 [==============================] - 1s 840us/step - loss: 0.6448 - accuracy: 0.6239 - val_loss: 0.6366 - val_accuracy: 0.6435\n",
      "Epoch 40/50\n",
      "974/974 [==============================] - 1s 848us/step - loss: 0.6390 - accuracy: 0.6326 - val_loss: 0.6327 - val_accuracy: 0.6351\n",
      "Epoch 41/50\n",
      "974/974 [==============================] - 1s 835us/step - loss: 0.6481 - accuracy: 0.6234 - val_loss: 0.7334 - val_accuracy: 0.5592\n",
      "Epoch 42/50\n",
      "974/974 [==============================] - 1s 834us/step - loss: 0.6455 - accuracy: 0.6251 - val_loss: 0.6390 - val_accuracy: 0.6169\n",
      "Epoch 43/50\n",
      "974/974 [==============================] - 1s 818us/step - loss: 0.6505 - accuracy: 0.6250 - val_loss: 0.6321 - val_accuracy: 0.6391\n",
      "Epoch 44/50\n",
      "974/974 [==============================] - 1s 855us/step - loss: 0.6430 - accuracy: 0.6277 - val_loss: 0.6771 - val_accuracy: 0.6312\n",
      "Epoch 45/50\n",
      "974/974 [==============================] - 1s 844us/step - loss: 0.6398 - accuracy: 0.6318 - val_loss: 0.6465 - val_accuracy: 0.6060\n",
      "Epoch 46/50\n",
      "974/974 [==============================] - 1s 864us/step - loss: 0.6393 - accuracy: 0.6325 - val_loss: 0.8243 - val_accuracy: 0.5636\n",
      "Epoch 47/50\n",
      "974/974 [==============================] - 1s 845us/step - loss: 0.6426 - accuracy: 0.6317 - val_loss: 0.6443 - val_accuracy: 0.6341\n",
      "Epoch 48/50\n",
      "974/974 [==============================] - 1s 835us/step - loss: 0.6455 - accuracy: 0.6274 - val_loss: 0.6529 - val_accuracy: 0.6336\n",
      "Epoch 49/50\n",
      "974/974 [==============================] - 1s 823us/step - loss: 0.6326 - accuracy: 0.6387 - val_loss: 0.6486 - val_accuracy: 0.6430\n",
      "Epoch 50/50\n",
      "974/974 [==============================] - 1s 837us/step - loss: 0.6363 - accuracy: 0.6329 - val_loss: 0.6348 - val_accuracy: 0.6391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb339412a70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_dataset2_train, y_dataset2_train, epochs=50, batch_size=64, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.save('models/keras_model2_leaky63.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/64 [..............................] - ETA: 0s - loss: 0.6500 - accuracy: 0.6250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 953us/step - loss: 0.6348 - accuracy: 0.6391\n",
      "Loss: 0.6347746253013611\n",
      "Accuracy: 0.639053225517273\n"
     ]
    }
   ],
   "source": [
    "results=model2.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entrenamiento de un tercer modelo secuancial con capas densas y activacion relu y LeakyReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "YOUR_INPUT_DIM=len(x_dataset2_test.columns)\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(30, activation=\"relu\", input_dim=YOUR_INPUT_DIM))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(70, activation=LeakyReLU(alpha=0.06)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(50, activation=LeakyReLU(alpha=0.06)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(25, activation=\"relu\"))\n",
    "model3.add(Dense(units=1, activation='sigmoid'))  \n",
    "model3.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "917/917 [==============================] - 2s 1ms/step - loss: 73.2640 - accuracy: 0.5072 - val_loss: 0.7801 - val_accuracy: 0.5498\n",
      "Epoch 2/55\n",
      "917/917 [==============================] - 1s 988us/step - loss: 1.2155 - accuracy: 0.5121 - val_loss: 0.6913 - val_accuracy: 0.5498\n",
      "Epoch 3/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.8162 - accuracy: 0.5310 - val_loss: 0.6885 - val_accuracy: 0.5498\n",
      "Epoch 4/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.7966 - accuracy: 0.5449 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 5/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.7406 - accuracy: 0.5481 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 6/55\n",
      "917/917 [==============================] - 1s 935us/step - loss: 0.7268 - accuracy: 0.5492 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 7/55\n",
      "917/917 [==============================] - 1s 943us/step - loss: 0.6933 - accuracy: 0.5498 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 8/55\n",
      "917/917 [==============================] - 1s 941us/step - loss: 0.7522 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 9/55\n",
      "917/917 [==============================] - 1s 940us/step - loss: 0.6888 - accuracy: 0.5499 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 10/55\n",
      "917/917 [==============================] - 1s 958us/step - loss: 0.6925 - accuracy: 0.5501 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 11/55\n",
      "917/917 [==============================] - 1s 978us/step - loss: 0.6884 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 12/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 13/55\n",
      "917/917 [==============================] - 1s 995us/step - loss: 0.6886 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 14/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 15/55\n",
      "917/917 [==============================] - 1s 965us/step - loss: 0.6883 - accuracy: 0.5499 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 16/55\n",
      "917/917 [==============================] - 1s 977us/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 17/55\n",
      "917/917 [==============================] - 1s 906us/step - loss: 0.6884 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 18/55\n",
      "917/917 [==============================] - 1s 936us/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 19/55\n",
      "917/917 [==============================] - 1s 929us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 20/55\n",
      "917/917 [==============================] - 1s 948us/step - loss: 0.7047 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 21/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 22/55\n",
      "917/917 [==============================] - 1s 918us/step - loss: 0.6932 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 23/55\n",
      "917/917 [==============================] - 1s 957us/step - loss: 0.6899 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 24/55\n",
      "917/917 [==============================] - 1s 978us/step - loss: 0.6930 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 25/55\n",
      "917/917 [==============================] - 1s 950us/step - loss: 0.6922 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 26/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 27/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.7216 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 28/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 29/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 30/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6935 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 31/55\n",
      "917/917 [==============================] - 1s 948us/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 32/55\n",
      "917/917 [==============================] - 1s 941us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 33/55\n",
      "917/917 [==============================] - 1s 944us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 34/55\n",
      "917/917 [==============================] - 1s 942us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 35/55\n",
      "917/917 [==============================] - 1s 938us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 36/55\n",
      "917/917 [==============================] - 1s 971us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 37/55\n",
      "917/917 [==============================] - 1s 957us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 38/55\n",
      "917/917 [==============================] - 1s 957us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 39/55\n",
      "917/917 [==============================] - 1s 959us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 40/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6881 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 41/55\n",
      "917/917 [==============================] - 1s 1ms/step - loss: 0.6944 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 42/55\n",
      "917/917 [==============================] - 1s 933us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 43/55\n",
      "917/917 [==============================] - 1s 946us/step - loss: 0.7051 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 44/55\n",
      "917/917 [==============================] - 1s 923us/step - loss: 0.6944 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 45/55\n",
      "917/917 [==============================] - 1s 935us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 46/55\n",
      "917/917 [==============================] - 1s 951us/step - loss: 0.6925 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 47/55\n",
      "917/917 [==============================] - 1s 946us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 48/55\n",
      "917/917 [==============================] - 1s 941us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 49/55\n",
      "917/917 [==============================] - 1s 944us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 50/55\n",
      "917/917 [==============================] - 1s 949us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 51/55\n",
      "917/917 [==============================] - 1s 960us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 52/55\n",
      "917/917 [==============================] - 1s 946us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 53/55\n",
      "917/917 [==============================] - 1s 943us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 54/55\n",
      "917/917 [==============================] - 1s 926us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n",
      "Epoch 55/55\n",
      "917/917 [==============================] - 1s 942us/step - loss: 0.6882 - accuracy: 0.5500 - val_loss: 0.6882 - val_accuracy: 0.5498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb329c54eb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_dataset2_train, y_dataset2_train, epochs=55, batch_size=68, validation_data=(x_dataset2_test,y_dataset2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.save('models/keras_model3_64_relu_leaky.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 980us/step - loss: 0.6882 - accuracy: 0.5498\n",
      "Loss: 0.6881910562515259\n",
      "Accuracy: 0.5498027801513672\n"
     ]
    }
   ],
   "source": [
    "results=model3.evaluate(x_dataset2_test,y_dataset2_test)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
